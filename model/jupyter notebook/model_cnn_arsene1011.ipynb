{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a48a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (6.17.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (6.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (5.9.4)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (7.4.5)\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (1.6.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (8.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (21.3)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (24.0.1)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipykernel) (1.5.6)\n",
      "Requirement already satisfied: backcall in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.13.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.32)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (5.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from packaging->ipykernel) (3.0.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel) (304)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\paulc\\anaconda3\\envs\\colas\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec35017f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!conda activate colas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1faf150-84dc-439b-a5fd-15075b9817d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: La procédure spécifiée est introuvable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Image, Dataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoFeatureExtractor, ViTFeatureExtractor,ViTForImageClassification,TrainingArguments, Trainer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     CenterCrop,\n\u001b[0;32m      7\u001b[0m     Compose,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     Resize,\n\u001b[0;32m     12\u001b[0m     ToTensor)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colas\\lib\\site-packages\\datasets\\__init__.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.6.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplatform\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(platform\u001b[38;5;241m.\u001b[39mpython_version()) \u001b[38;5;241m<\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.7\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\colas\\lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: La procédure spécifiée est introuvable."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset, Image, Dataset\n",
    "from transformers import AutoFeatureExtractor, ViTFeatureExtractor,ViTForImageClassification,TrainingArguments, Trainer\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor)\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0d51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d01dd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80e72d460614a409119b1ed57f7c588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8deca57-307f-4054-bf15-bfe5ac86ce26",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cba61bd-71f3-4ff3-a3ee-536263f3c23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'hfactory_magic_folders/colas_data_challenge/computer_vision_challenge/dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhfactory_magic_folders/colas_data_challenge/computer_vision_challenge/dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'hfactory_magic_folders/colas_data_challenge/computer_vision_challenge/dataset'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"hfactory_magic_folders/colas_data_challenge/computer_vision_challenge/dataset\")\n",
    "data = pd.read_csv('labels_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d40426-1107-4fd6-90fa-1fc08493cd85",
   "metadata": {},
   "source": [
    "# Converting images to dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64691d35-d7f2-4745-80ee-314f5c384b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing all the paths to images in a dict\n",
    "path_start = \"/mnt/internal/colas_data_challenge/computer_vision_challenge/datasets/dataset/train/\"\n",
    "list_path = [path_start + filename for filename in os.listdir('train')]\n",
    "path_dict = {\"image\": list_path}\n",
    "\n",
    "# Converting the dict to a dataset object\n",
    "dataset = Dataset.from_dict(path_dict).cast_column(\"image\", Image())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce59a7-0b5e-4c77-bb10-e5f9dfdde5cd",
   "metadata": {},
   "source": [
    "# Label management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dae3868-4b19-4542-b85f-a6c9d114404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1d0ab6-3a7b-409a-b1be-1c16ccc36038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REPARATION'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "id2label[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5a048-1412-4a4c-b9ff-90ae95b12d73",
   "metadata": {},
   "source": [
    "# Extracting pixel data from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b77b53c-85ce-40a9-8a0f-da2420159c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"google/vit-base-patch16-224\" # pre-trained model from which to fine-tune\n",
    "batch_size = 4 # batch size for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042b660d-f3aa-4bf8-8858-33e442152c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_checkpoint)\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a227429-c0a8-4de0-99e6-f4133c947860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data augmentation fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7136905-8302-4f44-8b22-601c654ba793",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4370f6-ab3e-4058-9cfb-3ff3a1ba6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up training into training + validation\n",
    "splits = dataset.train_test_split(test_size=0.1)\n",
    "train_ds = splits['train']\n",
    "val_ds = splits['test']\n",
    "\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561591f9-0356-4375-8130-8d59ac3da651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    problem_type=\"multi_label_classification\",\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc640e2-a519-47c0-b585-68a4f60d0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-eurosat\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6f3ed1-fc63-4c3b-8697-c15fb6aa8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the compute_metrics function takes a Named Tuple as input:\n",
    "# predictions, which are the logits of the model as Numpy arrays,\n",
    "# and label_ids, which are the ground-truth labels as Numpy arrays.\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16833767-c878-47a2-9fba-1a672daa1ad1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: 'vit-base-patch16-224-finetuned-eurosat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m train_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# rest is optional but nice to have\u001b[39;00m\n",
      "File \u001b[0;32m~/code-environments/colas/lib/python3.8/site-packages/transformers/trainer.py:489\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# Create clone of distant repo and output directory if needed\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_git_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# In case of pull, we need to make sure every process has the latest.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[0;32m~/code-environments/colas/lib/python3.8/site-packages/transformers/trainer.py:3284\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[0;34m(self, at_init)\u001b[0m\n\u001b[1;32m   3281\u001b[0m     repo_name \u001b[38;5;241m=\u001b[39m get_full_repo_name(repo_name, token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_token)\n\u001b[1;32m   3283\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m \u001b[43mRepository\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3287\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhub_private_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m   3291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moverwrite_output_dir \u001b[38;5;129;01mand\u001b[39;00m at_init:\n\u001b[1;32m   3292\u001b[0m         \u001b[38;5;66;03m# Try again after wiping output_dir\u001b[39;00m\n",
      "File \u001b[0;32m~/code-environments/colas/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:98\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m     97\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code-environments/colas/lib/python3.8/site-packages/huggingface_hub/repository.py:489\u001b[0m, in \u001b[0;36mRepository.__init__\u001b[0;34m(self, local_dir, clone_from, repo_type, use_auth_token, git_user, git_email, revision, private, skip_lfs_files, client)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;129m@_deprecate_arguments\u001b[39m(\n\u001b[1;32m    425\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.12\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m     deprecated_args\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m     client: Optional[HfApi] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m ):\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    Instantiate a local clone of a git repo.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m            instance will be created if this is left to `None`.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), local_dir)\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repo_type \u001b[38;5;241m=\u001b[39m repo_type\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: 'vit-base-patch16-224-finetuned-eurosat'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn\n",
    ")\n",
    "\n",
    "train_results = trainer.train()\n",
    "# rest is optional but nice to have\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2522f-0fcc-4b4d-b98c-52d8c1193832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
